{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc955890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from idd_forecast_mbp.helper_functions import check_column_for_problematic_values\n",
    "from idd_forecast_mbp.rake_and_aggregate_functions import make_aa_df_square, prep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37fbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from rra_tools.shell_tools import mkdir  # type: ignore\n",
    "from idd_forecast_mbp import constants as rfc\n",
    "from idd_forecast_mbp.helper_functions import check_column_for_problematic_values\n",
    "from idd_forecast_mbp.parquet_functions import read_parquet_with_integer_ids, write_parquet\n",
    "from idd_forecast_mbp.cause_processing_functions import format_aa_gbd_df, process_lsae_df\n",
    "from idd_forecast_mbp.rake_and_aggregate_functions import rake_aa_count_lsae_to_gbd, make_aa_full_rate_df_from_aa_count_df, check_concordance, aggregate_aa_rate_lsae_to_gbd\n",
    "\n",
    "\n",
    "PROCESSED_DATA_PATH = rfc.PROCESSED_DATA_PATH\n",
    "\n",
    "GBD_DATA_PATH = rfc.GBD_DATA_PATH\n",
    "LSAE_INPUT_PATH = rfc.LSAE_INPUT_PATH\n",
    "\n",
    "aa_full_malaria_df_path = PROCESSED_DATA_PATH / \"aa_full_malaria_df.parquet\"\n",
    "aa_full_dengue_df_path = PROCESSED_DATA_PATH / \"aa_full_dengue_df.parquet\"\n",
    "################################################################\n",
    "#### Hierarchy Paths, loading, and cleaning\n",
    "################################################################\n",
    "\n",
    "aa_full_population_df_path = f\"{PROCESSED_DATA_PATH}/aa_2023_full_population.parquet\"\n",
    "full_2023_hierarchy_path = f\"{PROCESSED_DATA_PATH}/full_hierarchy_2023_lsae_1209.parquet\"\n",
    "\n",
    "hierarchy_df = read_parquet_with_integer_ids(full_2023_hierarchy_path)\n",
    "aa_full_population_df = pd.read_parquet(aa_full_population_df_path)\n",
    "\n",
    "aa_gbd_malaria_df_path = f\"{GBD_DATA_PATH}/gbd_2023_malaria_aa.csv\"\n",
    "aa_gbd_dengue_df_path = f\"{GBD_DATA_PATH}/gbd_2023_dengue_aa.csv\"\n",
    "\n",
    "measure_map = rfc.measure_map\n",
    "ploblematic_rule_map = rfc.problematic_rule_map\n",
    "\n",
    "################################################################\n",
    "###  MALARIA DATA PROCESSING AND RAKING\n",
    "################################################################\n",
    "\n",
    "###----------------------------------------------------------###\n",
    "### 1. Data Loading - Get raw data sources\n",
    "### Imports raw malaria prevalence data (PfPR) and reference GBD datasets needed for raking.\n",
    "### These foundational datasets provide the base inputs for all subsequent processing.\n",
    "###----------------------------------------------------------###\n",
    "\n",
    "# Load PfPR (parasite prevalence) and GBD reference data\n",
    "aa_lsae_malaria_pfpr_df = process_lsae_df(\"malaria\", \"pfpr\", aa_full_population_df, hierarchy_df)\n",
    "aa_full_malaria_pfpr_df = aggregate_aa_rate_lsae_to_gbd(rate_variable = \"malaria_pfpr\", hierarchy_df = hierarchy_df, aa_lsae_rate_df = aa_lsae_malaria_pfpr_df, aa_full_population_df=aa_full_population_df, return_full_df = True)\n",
    "\n",
    "# Load GBD reference data for raking\n",
    "aa_gbd_malaria_df = pd.read_csv(aa_gbd_malaria_df_path, low_memory=False)\n",
    "\n",
    "###----------------------------------------------------------###\n",
    "### 2. Incidence Processing & Raking\n",
    "### This section processes malaria incidence data, including counts and rates.\n",
    "### It formats the GBD data, processes the LSAE data, and then rakes the incidence counts\n",
    "### to the GBD data. Finally, it calculates incidence rates from the counts.\n",
    "###----------------------------------------------------------###\n",
    "cause = 'malaria'\n",
    "measure = 'incidence'\n",
    "short_measure = measure_map[measure]['short']\n",
    "metric = 'count'\n",
    "count_variable = f'{cause}_{short_measure}_{metric}'\n",
    "rate_variable = f'{cause}_{short_measure}_rate'\n",
    "\n",
    "problematic_rules = ploblematic_rule_map[cause][measure]\n",
    "\n",
    "aa_inc_gbd_count_df = format_aa_gbd_df(cause, 'incidence', 'count', aa_gbd_malaria_df)\n",
    "aa_mort_gbd_count_df = format_aa_gbd_df(cause, 'mortality', 'count', aa_gbd_malaria_df)\n",
    "aa_gbd_count_df = aa_inc_gbd_count_df.merge(\n",
    "    aa_mort_gbd_count_df,\n",
    "    on=[\"location_id\", \"year_id\"],\n",
    "    how=\"left\")\n",
    "aa_gbd_count_df = aa_gbd_count_df.merge(\n",
    "    aa_full_population_df,\n",
    "    on=[\"location_id\", \"year_id\"],\n",
    "    how=\"left\")\n",
    "\n",
    "aa_inc_lsae_count_df = process_lsae_df(cause, 'incidence', aa_full_population_df, hierarchy_df)\n",
    "aa_mort_lsae_count_df = process_lsae_df(cause, 'mortality', aa_full_population_df, hierarchy_df)\n",
    "aa_lsae_count_df = aa_inc_lsae_count_df.merge(\n",
    "    aa_mort_lsae_count_df[[\"location_id\", \"year_id\", \"malaria_mort_count\"]],\n",
    "    on=[\"location_id\", \"year_id\"],\n",
    "    how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d344c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aa_full_malaria_inc_count_df = rake_aa_count_lsae_to_gbd(count_variable = count_variable, \n",
    "#                                                  hierarchy_df =hierarchy_df, \n",
    "#                                                  aa_gbd_count_df = aa_gbd_count_df, \n",
    "#                                                  aa_lsae_count_df = aa_lsae_count_df,\n",
    "#                                                  problematic_rules = problematic_rules,\n",
    "#                                                  aa_full_count_df_path = None, return_full_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5268a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_count_variable = 'malaria_inc_count'\n",
    "mort_count_variable = 'malaria_mort_count'\n",
    "hierarchy_df = hierarchy_df\n",
    "aa_gbd_count_df = aa_gbd_count_df\n",
    "aa_lsae_count_df = aa_lsae_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0229b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_variables = [inc_count_variable, mort_count_variable]\n",
    "aa_gbd_count_df = prep_df(aa_gbd_count_df, hierarchy_df)\n",
    "aa_gbd_count_df['cfr'] = aa_gbd_count_df[mort_count_variable] / aa_gbd_count_df[inc_count_variable]\n",
    "aa_gbd_count_df.loc[aa_gbd_count_df[mort_count_variable] == 0, 'cfr'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c895e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_gbd_count_0_to_3_df = aa_gbd_count_df[aa_gbd_count_df['level'] <= 3].copy()\n",
    "\n",
    "aa_lsae_count_df = prep_df(aa_lsae_count_df, hierarchy_df)\n",
    "aa_lsae_count_df = make_aa_df_square(count_variables, aa_lsae_count_df, hierarchy_df, level_start = 3, level_end = 5)\n",
    "aa_lsae_count_df['cfr'] = aa_lsae_count_df[mort_count_variable] / aa_lsae_count_df[inc_count_variable]\n",
    "aa_lsae_count_df.loc[aa_lsae_count_df[mort_count_variable] == 0, 'cfr'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d4a3d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in count_variables + ['cfr']:\n",
    "    aa_gbd_count_df[f'{variable}_gbd'] = aa_gbd_count_df[variable]\n",
    "\n",
    "gbd_variables = [f'{variable}_gbd' for variable in count_variables + ['cfr']]\n",
    "\n",
    "aa_gbd_count_df['set_by_gbd'] = True\n",
    "\n",
    "aa_lsae_count_df = aa_lsae_count_df.merge(\n",
    "    aa_gbd_count_df[['location_id', 'year_id', 'set_by_gbd'] + gbd_variables],\n",
    "    on=['location_id', 'year_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24abc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track which locations are already set by GBD\n",
    "mask = aa_lsae_count_df['set_by_gbd'].isna()\n",
    "aa_lsae_count_df.loc[mask, 'set_by_gbd'] = False\n",
    "aa_lsae_count_df['set_by_gbd'] = aa_lsae_count_df['set_by_gbd'].astype('boolean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d64780c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle all count variables and CFR\n",
    "for var in count_variables + ['cfr']:\n",
    "    aa_lsae_count_df[var] = aa_lsae_count_df[f'{var}_gbd'].fillna(aa_lsae_count_df[var])\n",
    "    aa_lsae_count_df = aa_lsae_count_df.drop(columns=[f'{var}_gbd'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b5fe7",
   "metadata": {},
   "source": [
    "Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1aabbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_m1_df = aa_gbd_count_0_to_3_df[aa_gbd_count_0_to_3_df['level'] == 3].copy()\n",
    "level_df = aa_lsae_count_df[aa_lsae_count_df['level'] == 4].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a43005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict = {'location_id': 'parent_id'}\n",
    "for var in count_variables + ['cfr']:\n",
    "    rename_dict[var] = f'parent_{var}'\n",
    "\n",
    "parent_columns = list(rename_dict.values())\n",
    "\n",
    "level_m1_df = level_m1_df.rename(columns=rename_dict)\n",
    "\n",
    "level_df = level_df.merge(\n",
    "    hierarchy_df[['location_id', 'parent_id']],\n",
    "    on='location_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0887e39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df['current_mortality_rate'] = level_df[mort_count_variable] / level_df['population']\n",
    "level_df['current_incidence_rate'] = level_df[inc_count_variable] / level_df['population']\n",
    "level_df['current_cfr'] = level_df[mort_count_variable] / level_df[inc_count_variable]\n",
    "\n",
    "# Replace NaN and Inf values with 0 for all current rate columns\n",
    "current_rate_cols = ['current_mortality_rate', 'current_incidence_rate', 'current_cfr']\n",
    "for col in current_rate_cols:\n",
    "    level_df[col] = level_df[col].replace([np.inf, -np.inf, np.nan], 0)\n",
    "# If any of the three 'current_' variables are 0, set 'effective_population' to 0\n",
    "level_df['effective_population'] = np.where(\n",
    "    (level_df['current_mortality_rate'] == 0) |\n",
    "    (level_df['current_incidence_rate'] == 0) |\n",
    "    (level_df['current_cfr'] == 0),\n",
    "    0,\n",
    "    level_df['population']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc00ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all count variables and CFR by parent_id\n",
    "agg_dict = {\n",
    "    'population': 'sum',\n",
    "    'effective_population': 'sum'\n",
    "}\n",
    "for var in count_variables:\n",
    "    agg_dict[var] = 'sum'\n",
    "\n",
    "level_m1_agg_df = level_df.groupby(['parent_id', 'year_id']).agg(agg_dict).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "adea2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_m1_agg_df = level_m1_agg_df.rename(columns={'population': 'parent_population'})\n",
    "level_m1_agg_df = level_m1_agg_df.rename(columns={'effective_population': 'parent_effective_population'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1153f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de6f979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in the level - 1 df\n",
    "level_m1_agg_df = level_m1_agg_df.merge(\n",
    "    level_m1_df[['year_id'] + parent_columns],\n",
    "    on=['year_id', 'parent_id'],\n",
    "    how='left'\n",
    ")\n",
    "level_m1_agg_df['cfr'] = level_m1_agg_df[mort_count_variable] / level_m1_agg_df[inc_count_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ce6e38dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>year_id</th>\n",
       "      <th>parent_population</th>\n",
       "      <th>parent_effective_population</th>\n",
       "      <th>malaria_inc_count</th>\n",
       "      <th>malaria_mort_count</th>\n",
       "      <th>parent_malaria_inc_count</th>\n",
       "      <th>parent_malaria_mort_count</th>\n",
       "      <th>parent_cfr</th>\n",
       "      <th>cfr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.258333e+09</td>\n",
       "      <td>5.011522e+07</td>\n",
       "      <td>6.075997e+04</td>\n",
       "      <td>22.050010</td>\n",
       "      <td>6.075997e+04</td>\n",
       "      <td>22.050010</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2001</td>\n",
       "      <td>1.263712e+09</td>\n",
       "      <td>5.053049e+07</td>\n",
       "      <td>4.580781e+04</td>\n",
       "      <td>25.828507</td>\n",
       "      <td>4.580781e+04</td>\n",
       "      <td>25.828507</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2002</td>\n",
       "      <td>1.269927e+09</td>\n",
       "      <td>5.098043e+07</td>\n",
       "      <td>5.283493e+04</td>\n",
       "      <td>44.653627</td>\n",
       "      <td>5.283493e+04</td>\n",
       "      <td>44.653627</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2003</td>\n",
       "      <td>1.276870e+09</td>\n",
       "      <td>5.145764e+07</td>\n",
       "      <td>5.823846e+04</td>\n",
       "      <td>34.619070</td>\n",
       "      <td>5.823846e+04</td>\n",
       "      <td>34.619070</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2004</td>\n",
       "      <td>1.284501e+09</td>\n",
       "      <td>5.195527e+07</td>\n",
       "      <td>5.329673e+04</td>\n",
       "      <td>39.579923</td>\n",
       "      <td>5.329673e+04</td>\n",
       "      <td>39.579923</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>522</td>\n",
       "      <td>2018</td>\n",
       "      <td>3.480359e+07</td>\n",
       "      <td>3.480359e+07</td>\n",
       "      <td>1.733528e+06</td>\n",
       "      <td>2102.198346</td>\n",
       "      <td>2.199947e+06</td>\n",
       "      <td>2743.228159</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>522</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.560610e+07</td>\n",
       "      <td>3.560610e+07</td>\n",
       "      <td>1.996085e+06</td>\n",
       "      <td>2201.875475</td>\n",
       "      <td>2.524225e+06</td>\n",
       "      <td>2777.029989</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>522</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.614354e+07</td>\n",
       "      <td>3.614354e+07</td>\n",
       "      <td>2.198147e+06</td>\n",
       "      <td>2546.554656</td>\n",
       "      <td>2.681114e+06</td>\n",
       "      <td>3198.802707</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>522</td>\n",
       "      <td>2021</td>\n",
       "      <td>3.656424e+07</td>\n",
       "      <td>3.656424e+07</td>\n",
       "      <td>2.186278e+06</td>\n",
       "      <td>2686.098845</td>\n",
       "      <td>2.673778e+06</td>\n",
       "      <td>3210.596273</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>522</td>\n",
       "      <td>2022</td>\n",
       "      <td>3.702108e+07</td>\n",
       "      <td>3.702108e+07</td>\n",
       "      <td>2.238876e+06</td>\n",
       "      <td>2048.522335</td>\n",
       "      <td>2.698031e+06</td>\n",
       "      <td>3237.382400</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4692 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      parent_id  year_id  parent_population  parent_effective_population  \\\n",
       "0             6     2000       1.258333e+09                 5.011522e+07   \n",
       "1             6     2001       1.263712e+09                 5.053049e+07   \n",
       "2             6     2002       1.269927e+09                 5.098043e+07   \n",
       "3             6     2003       1.276870e+09                 5.145764e+07   \n",
       "4             6     2004       1.284501e+09                 5.195527e+07   \n",
       "...         ...      ...                ...                          ...   \n",
       "4687        522     2018       3.480359e+07                 3.480359e+07   \n",
       "4688        522     2019       3.560610e+07                 3.560610e+07   \n",
       "4689        522     2020       3.614354e+07                 3.614354e+07   \n",
       "4690        522     2021       3.656424e+07                 3.656424e+07   \n",
       "4691        522     2022       3.702108e+07                 3.702108e+07   \n",
       "\n",
       "      malaria_inc_count  malaria_mort_count  parent_malaria_inc_count  \\\n",
       "0          6.075997e+04           22.050010              6.075997e+04   \n",
       "1          4.580781e+04           25.828507              4.580781e+04   \n",
       "2          5.283493e+04           44.653627              5.283493e+04   \n",
       "3          5.823846e+04           34.619070              5.823846e+04   \n",
       "4          5.329673e+04           39.579923              5.329673e+04   \n",
       "...                 ...                 ...                       ...   \n",
       "4687       1.733528e+06         2102.198346              2.199947e+06   \n",
       "4688       1.996085e+06         2201.875475              2.524225e+06   \n",
       "4689       2.198147e+06         2546.554656              2.681114e+06   \n",
       "4690       2.186278e+06         2686.098845              2.673778e+06   \n",
       "4691       2.238876e+06         2048.522335              2.698031e+06   \n",
       "\n",
       "      parent_malaria_mort_count  parent_cfr       cfr  \n",
       "0                     22.050010    0.000363  0.000363  \n",
       "1                     25.828507    0.000564  0.000564  \n",
       "2                     44.653627    0.000845  0.000845  \n",
       "3                     34.619070    0.000594  0.000594  \n",
       "4                     39.579923    0.000743  0.000743  \n",
       "...                         ...         ...       ...  \n",
       "4687                2743.228159    0.001247  0.001213  \n",
       "4688                2777.029989    0.001100  0.001103  \n",
       "4689                3198.802707    0.001193  0.001159  \n",
       "4690                3210.596273    0.001201  0.001229  \n",
       "4691                3237.382400    0.001200  0.000915  \n",
       "\n",
       "[4692 rows x 10 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_m1_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "356ff0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_m1_agg_df[f'{mort_count_variable}_rakingfactor'] = level_m1_agg_df[mort_count_variable] / level_m1_agg_df[f'parent_{mort_count_variable}']\n",
    "level_m1_agg_df[f'{inc_count_variable}_rakingfactor'] = level_m1_agg_df[inc_count_variable] / level_m1_agg_df[f'parent_{inc_count_variable}']\n",
    "level_m1_agg_df['cfr_rakingfactor'] = level_m1_agg_df['cfr'] / level_m1_agg_df['parent_cfr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da70ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in count_variables + ['cfr']:\n",
    "    level_m1_agg_df[f'full_population_{var}_rakingfactor'] = level_m1_agg_df[f'parent_{var}'] / level_m1_agg_df['parent_population']\n",
    "    level_m1_agg_df[f'population_{var}_rakingfactor'] = level_m1_agg_df[f'parent_{var}'] / level_m1_agg_df['parent_effective_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2740cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in count_variables + ['cfr']:\n",
    "    # set the raking factor to 0 where the parent count is 0\n",
    "    level_m1_agg_df.loc[level_m1_agg_df[f'parent_{var}'] == 0, f'{var}_rakingfactor'] = 0\n",
    "    level_m1_agg_df.loc[level_m1_agg_df[f'parent_{var}'] == 0, f'full_population_{var}_rakingfactor'] = 0\n",
    "    level_m1_agg_df.loc[level_m1_agg_df[f'parent_{var}'] == 0, f'population_{var}_rakingfactor'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0743c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the list of columns to merge for all variables\n",
    "merge_cols = ['year_id', 'parent_id']\n",
    "\n",
    "# Add parent variables\n",
    "for var in count_variables + ['cfr']:\n",
    "    merge_cols.append(f'parent_{var}')\n",
    "    merge_cols.append(f'{var}_rakingfactor')\n",
    "    merge_cols.append(f'full_population_{var}_rakingfactor')\n",
    "    merge_cols.append(f'population_{var}_rakingfactor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df = level_df.merge(\n",
    "    level_m1_agg_df[merge_cols],\n",
    "    on=['year_id', 'parent_id'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a3543",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# replace population_raking_factor with full_population_raking_factor if population_raking_factor is inf or the rate we will get if we use effective will be too high\n",
    "level_df['used_full_population_raking_factor'] = np.where(level_df['population_raking_factor'] > problematic_rules['rate_max'][level], True, False)\n",
    "level_df['population_raking_factor'] = np.where(level_df['population_raking_factor'] > problematic_rules['rate_max'][level], level_df['full_population_raking_factor'], level_df['population_raking_factor'])\n",
    "# drop zero_population_raking_factor\n",
    "level_df = level_df.drop(columns=['full_population_raking_factor'])\n",
    "\n",
    "# Setting up which populaiton to use for raking and multiplying\n",
    "effective_population_mask = level_df['used_full_population_raking_factor'] == False\n",
    "level_df['population_to_use'] = level_df['population']\n",
    "level_df.loc[effective_population_mask,'population_to_use'] = level_df.loc[effective_population_mask,'effective_population']\n",
    "\n",
    "level_df['count_based_count'] = level_df[count_variable] * level_df['count_raking_factor']\n",
    "level_df['population_based_count'] = level_df['population_to_use'] * level_df['population_raking_factor']\n",
    "\n",
    "# Always use the actual population here!\n",
    "level_df['count_based_rate'] = level_df['count_based_count'] / level_df['population']\n",
    "level_df['population_based_rate'] = level_df['population_based_count'] / level_df['population']\n",
    "level_df['parent_year_id'] = level_df['parent_id'].astype(str).str.cat(level_df['year_id'].astype(str), sep='_')\n",
    "\n",
    "# Which level_df rows have either count_raking_factor = inf or count_based_rate is big\n",
    "problematic_rows = level_df[(level_df['count_raking_factor'] > problematic_rules['count_raking_factor_max']) | \n",
    "                            (level_df['count_based_rate'] > problematic_rules['rate_max'][level]) | \n",
    "                            ((level_df['count_raking_factor'] > problematic_rules['count_raking_factor_conditional']) & (level_df['count_based_rate'] > problematic_rules['rate_max_conditional']))]\n",
    "problematic_rows = problematic_rows[problematic_rows['count_based_rate'] > problematic_rows['population_based_rate']]\n",
    "npinf_rows = level_df[(level_df['count_raking_factor'] == np.inf)]\n",
    "problematic_rows = pd.concat([problematic_rows, npinf_rows]).drop_duplicates()\n",
    "\n",
    "problematic_parent_years = problematic_rows['parent_year_id'].drop_duplicates().reset_index(drop=True).to_frame(name='parent_year_id')\n",
    "problematic_parent_years['use_population'] = True\n",
    "level_df = level_df.merge(\n",
    "    problematic_parent_years,\n",
    "    on='parent_year_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "mask = level_df['use_population'].isna()\n",
    "level_df.loc[mask, 'use_population'] = False\n",
    "level_df['use_population'] = level_df['use_population'].astype('boolean')\n",
    "\n",
    "# For rows where use_population is True\n",
    "population_mask = (level_df['use_population'] == True) & (level_df['set_by_gbd'] == False)\n",
    "count_mask = (level_df['use_population'] == False) & (level_df['set_by_gbd'] == False)\n",
    "left_alone = len(count_mask[count_mask == True])\n",
    "changed = len(population_mask[population_mask == True])\n",
    "total = left_alone + changed\n",
    "# Note we use 'population_to_use' here!!!\n",
    "level_df.loc[count_mask, count_variable] = level_df.loc[count_mask, count_variable] * level_df.loc[count_mask, 'count_raking_factor']\n",
    "level_df.loc[population_mask, count_variable] = level_df.loc[population_mask, 'population_to_use'] * level_df.loc[population_mask, 'population_raking_factor']\n",
    "    # Apply the raking factor to the count variable\n",
    "    \n",
    "drop_cols = [col for col in level_df.columns if 'based' in col or 'raking' in col] + ['parent_id', f'parent_{count_variable}', 'use_population', 'used_full_population_raking_factor', 'population_to_use', 'effective_population', 'parent_year_id', 'current_rate']\n",
    "# Drop the raking factor\n",
    "level_df = level_df.drop(columns=drop_cols)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f665d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d81f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107ad3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb8477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_level_at_once(variables, level_df, level_m1_df, problematic_rules, hierarchy_df, level):\n",
    "    '''\n",
    "    Rakes the level DataFrame to the next level using the hierarchy DataFrame.\n",
    "    '''\n",
    "    # Change the name of the count variable and prep for matching by parent_id from level\n",
    "    level_m1_df = level_m1_df.rename(columns={\n",
    "        count_variable: f'parent_{count_variable}',\n",
    "        'location_id': 'parent_id'})\n",
    "    # Prep the level df\n",
    "    # Add in parent_id\n",
    "    level_df = level_df.merge(\n",
    "        hierarchy_df[['location_id', 'parent_id']],\n",
    "        on='location_id',\n",
    "        how='left'\n",
    "    )\n",
    "    level_df['current_rate'] = level_df[count_variable] / level_df['population']\n",
    "    # Make a column called 'effective_population' that is equal to population where count_variable > 0, else 0\n",
    "    level_df['effective_population'] = np.where(level_df[count_variable] > 0, level_df['population'], 0)\n",
    "    # Aggregate the count variable by parent_id\n",
    "    level_m1_agg_df= level_df.groupby(['parent_id', 'year_id']).agg({\n",
    "        count_variable: 'sum',\n",
    "        'population': 'sum',\n",
    "        'effective_population': 'sum'\n",
    "    }).reset_index()\n",
    "    level_m1_agg_df = level_m1_agg_df.rename(columns={'population': 'parent_population'})\n",
    "    level_m1_agg_df = level_m1_agg_df.rename(columns={'effective_population': 'parent_effective_population'})\n",
    "    # Merge in the level - 1 df\n",
    "    level_m1_agg_df = level_m1_agg_df.merge(\n",
    "        level_m1_df[['year_id', 'parent_id', f'parent_{count_variable}']],\n",
    "        on=['year_id', 'parent_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    # Calculate the raking factor\n",
    "    level_m1_agg_df['count_raking_factor'] = level_m1_agg_df[f'parent_{count_variable}'] / level_m1_agg_df[count_variable]\n",
    "    level_m1_agg_df['full_population_raking_factor'] = level_m1_agg_df[f'parent_{count_variable}'] / level_m1_agg_df['parent_population']\n",
    "    level_m1_agg_df['population_raking_factor'] = level_m1_agg_df[f'parent_{count_variable}'] / level_m1_agg_df['parent_effective_population']\n",
    "    # Set the raking factor to 1 where the parent count variable is 0\n",
    "    level_m1_agg_df.loc[level_m1_agg_df[f'parent_{count_variable}'] == 0, 'count_raking_factor'] = 0\n",
    "    level_m1_agg_df.loc[level_m1_agg_df[f'parent_{count_variable}'] == 0, 'full_population_raking_factor'] = 0\n",
    "    level_m1_agg_df.loc[level_m1_agg_df[f'parent_{count_variable}'] == 0, 'population_raking_factor'] = 0\n",
    "\n",
    "\n",
    "    level_df = level_df.merge(\n",
    "        level_m1_agg_df[['year_id', 'parent_id', f'parent_{count_variable}','count_raking_factor', 'full_population_raking_factor', 'population_raking_factor']],\n",
    "        on=['year_id', 'parent_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # replace population_raking_factor with full_population_raking_factor if population_raking_factor is inf or the rate we will get if we use effective will be too high\n",
    "    level_df['used_full_population_raking_factor'] = np.where(level_df['population_raking_factor'] > problematic_rules['rate_max'][level], True, False)\n",
    "    level_df['population_raking_factor'] = np.where(level_df['population_raking_factor'] > problematic_rules['rate_max'][level], level_df['full_population_raking_factor'], level_df['population_raking_factor'])\n",
    "    # drop zero_population_raking_factor\n",
    "    level_df = level_df.drop(columns=['full_population_raking_factor'])\n",
    "\n",
    "    # Setting up which populaiton to use for raking and multiplying\n",
    "    effective_population_mask = level_df['used_full_population_raking_factor'] == False\n",
    "    level_df['population_to_use'] = level_df['population']\n",
    "    level_df.loc[effective_population_mask,'population_to_use'] = level_df.loc[effective_population_mask,'effective_population']\n",
    "\n",
    "    level_df['count_based_count'] = level_df[count_variable] * level_df['count_raking_factor']\n",
    "    level_df['population_based_count'] = level_df['population_to_use'] * level_df['population_raking_factor']\n",
    "\n",
    "    # Always use the actual population here!\n",
    "    level_df['count_based_rate'] = level_df['count_based_count'] / level_df['population']\n",
    "    level_df['population_based_rate'] = level_df['population_based_count'] / level_df['population']\n",
    "    level_df['parent_year_id'] = level_df['parent_id'].astype(str).str.cat(level_df['year_id'].astype(str), sep='_')\n",
    "\n",
    "    # Which level_df rows have either count_raking_factor = inf or count_based_rate is big\n",
    "    problematic_rows = level_df[(level_df['count_raking_factor'] > problematic_rules['count_raking_factor_max']) | \n",
    "                                (level_df['count_based_rate'] > problematic_rules['rate_max'][level]) | \n",
    "                                ((level_df['count_raking_factor'] > problematic_rules['count_raking_factor_conditional']) & (level_df['count_based_rate'] > problematic_rules['rate_max_conditional']))]\n",
    "    problematic_rows = problematic_rows[problematic_rows['count_based_rate'] > problematic_rows['population_based_rate']]\n",
    "    npinf_rows = level_df[(level_df['count_raking_factor'] == np.inf)]\n",
    "    problematic_rows = pd.concat([problematic_rows, npinf_rows]).drop_duplicates()\n",
    "\n",
    "    problematic_parent_years = problematic_rows['parent_year_id'].drop_duplicates().reset_index(drop=True).to_frame(name='parent_year_id')\n",
    "    problematic_parent_years['use_population'] = True\n",
    "    level_df = level_df.merge(\n",
    "        problematic_parent_years,\n",
    "        on='parent_year_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    mask = level_df['use_population'].isna()\n",
    "    level_df.loc[mask, 'use_population'] = False\n",
    "    level_df['use_population'] = level_df['use_population'].astype('boolean')\n",
    "\n",
    "    # For rows where use_population is True\n",
    "    population_mask = (level_df['use_population'] == True) & (level_df['set_by_gbd'] == False)\n",
    "    count_mask = (level_df['use_population'] == False) & (level_df['set_by_gbd'] == False)\n",
    "    left_alone = len(count_mask[count_mask == True])\n",
    "    changed = len(population_mask[population_mask == True])\n",
    "    total = left_alone + changed\n",
    "    # Note we use 'population_to_use' here!!!\n",
    "    level_df.loc[count_mask, count_variable] = level_df.loc[count_mask, count_variable] * level_df.loc[count_mask, 'count_raking_factor']\n",
    "    level_df.loc[population_mask, count_variable] = level_df.loc[population_mask, 'population_to_use'] * level_df.loc[population_mask, 'population_raking_factor']\n",
    "        # Apply the raking factor to the count variable\n",
    "        \n",
    "    drop_cols = [col for col in level_df.columns if 'based' in col or 'raking' in col] + ['parent_id', f'parent_{count_variable}', 'use_population', 'used_full_population_raking_factor', 'population_to_use', 'effective_population', 'parent_year_id', 'current_rate']\n",
    "    # Drop the raking factor\n",
    "    level_df = level_df.drop(columns=drop_cols)\n",
    "    #\n",
    "    # Additional mortality-specific checkslevel_df['current_rate'] = level_df[count_variable] / level_df['population']\n",
    "    mort_stats = {}\n",
    "    if 'malaria_mort_count' in count_variable.lower():\n",
    "        # Only calculate for numeric, non-problematic values\n",
    "        tmp_df = level_df.copy()\n",
    "        tmp_df['rate'] = tmp_df[count_variable] / tmp_df['population']\n",
    "        mort_stats = {\n",
    "            'mean': tmp_df['rate'].mean(),\n",
    "            'max': tmp_df['rate'].max(),\n",
    "            'count_gt_0_001': (tmp_df['rate'] > 0.001).sum(),\n",
    "            'count_gt_0_01': (tmp_df['rate'] > 0.01).sum(),\n",
    "            'count_gt_0_1': (tmp_df['rate'] > 0.1).sum(),\n",
    "            'count_gt_1': (tmp_df['rate'] > 1).sum()\n",
    "        }\n",
    "        print(f\"\\nMortality stats for {count_variable} at level {level}:\")\n",
    "        print(f\"Mortality Statistics:\")\n",
    "        print(f\"Mean: {mort_stats['mean']:.6f}\")\n",
    "        print(f\"Max: {mort_stats['max']:.6f}\")\n",
    "        print(f\"Count > 0.001: {mort_stats['count_gt_0_001']}\")\n",
    "        print(f\"Count > 0.01: {mort_stats['count_gt_0_01']}\")\n",
    "        print(f\"Count > 0.1: {mort_stats['count_gt_0_1']}\")\n",
    "        print(f\"Count > 1: {mort_stats['count_gt_1']}\")\n",
    "        print(f\"Changed {changed} ({100*(changed / total):.1f}%)rows, left alone {left_alone} rows, total {total} rows\")\n",
    "    return level_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fb970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87a4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "level_4_df = rake_level(count_variable, level_df, level_m1_df, problematic_rules, hierarchy_df, level = 4)\n",
    "# Rake 5 to 4\n",
    "level_m1_df = level_4_df.copy()\n",
    "level_df = aa_lsae_count_df[aa_lsae_count_df['level'] == 5].copy()\n",
    "level_df = make_aa_df_square(count_variable, level_df, hierarchy_df, 5, 5)\n",
    "level_5_df = rake_level(count_variable, level_df, level_m1_df, problematic_rules, hierarchy_df, level = 5)\n",
    "# Make aa_full_df\n",
    "aa_full_count_df = pd.concat([\n",
    "    aa_gbd_count_0_to_3_df,\n",
    "    level_4_df,\n",
    "    level_5_df\n",
    "], ignore_index=True)\n",
    "# Drop level column if it exists\n",
    "if 'level' in aa_full_count_df.columns:\n",
    "    aa_full_count_df = aa_full_count_df.drop(columns=['level'])\n",
    "\n",
    "# Save the aa_full_df\n",
    "if aa_full_count_df_path is not None:\n",
    "    write_parquet(aa_full_count_df, aa_full_count_df_path)\n",
    "# Return the full DataFrame if requested, return nothing otherwise\n",
    "if return_full_df:\n",
    "    return aa_full_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679705bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_aa_counts_lsae_to_gbd(inc_count_variable, mort_count_variable, hierarchy_df, \n",
    "                               aa_gbd_count_df, aa_lsae_count_df, \n",
    "                               problematic_rules):\n",
    "    '''\n",
    "    Rakes the LSAE age-aggregated data to match the GBD age-aggregated data.\n",
    "    '''\n",
    "    count_variables = [inc_count_variable, mort_count_variable]\n",
    "    aa_gbd_count_df = prep_df(aa_gbd_count_df, hierarchy_df)\n",
    "    aa_gbd_count_df['cfr'] = aa_gbd_count_df[mort_count_variable] / aa_gbd_count_df[inc_count_variable]\n",
    "    aa_gbd_count_df[aa_gbd_count_df[mort_count_variable] == 0, 'cfr'] = 0\n",
    "\n",
    "    aa_gbd_count_0_to_3_df = aa_gbd_count_df[aa_gbd_count_df['level'] <= 3].copy()\n",
    "\n",
    "    aa_lsae_count_df = prep_df(aa_lsae_count_df, hierarchy_df)\n",
    "    aa_lsae_count_df = make_aa_df_square(count_variables, hierarchy_df, level_start = 3, level_end = 5)\n",
    "    aa_lsae_count_df['cfr'] = aa_lsae_count_df[mort_count_variable] / aa_lsae_count_df[inc_count_variable]\n",
    "    aa_lsae_count_df[aa_lsae_count_df[mort_count_variable] == 0, 'cfr'] = 0\n",
    "\n",
    "\n",
    "    for variable in count_variables + ['cfr']:\n",
    "        aa_gbd_count_df[f'{variable}_gbd'] = aa_gbd_count_df[variable]\n",
    "    \n",
    "    gbd_variables = [f'{variable}_gbd' for variable in count_variables + ['cfr']]\n",
    "\n",
    "    aa_gbd_count_df['set_by_gbd'] = True\n",
    "    \n",
    "    aa_lsae_count_df = aa_lsae_count_df.merge(\n",
    "        aa_gbd_count_df[['location_id', 'year_id', 'set_by_gbd'] + gbd_variables],\n",
    "        on=['location_id', 'year_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "\n",
    "    # Track which locations are already set by GBD\n",
    "    mask = aa_lsae_count_df['set_by_gbd'].isna()\n",
    "    aa_lsae_count_df.loc[mask, 'set_by_gbd'] = False\n",
    "    aa_lsae_count_df['set_by_gbd'] = aa_lsae_count_df['set_by_gbd'].astype('boolean')\n",
    "\n",
    "    aa_lsae_count_df[count_variable] = aa_lsae_count_df[f'{count_variable}_gbd'].fillna(aa_lsae_count_df[count_variable])\n",
    "    aa_lsae_count_df = aa_lsae_count_df.drop(columns=[f'{count_variable}_gbd'])\n",
    "\n",
    "    # Rake 4 to 3 def make_aa_df_square(variable, df, hierarchy_df, level_start, level_end):\n",
    "    level_m1_df = aa_gbd_count_0_to_3_df[aa_gbd_count_0_to_3_df['level'] == 3].copy()\n",
    "    level_df = aa_lsae_count_df[aa_lsae_count_df['level'] == 4].copy()\n",
    "    level_df = make_aa_df_square(count_variable, level_df, hierarchy_df, 4, 4)\n",
    "    level_4_df = rake_level(count_variable, level_df, level_m1_df, problematic_rules, hierarchy_df, level = 4)\n",
    "    # Rake 5 to 4\n",
    "    level_m1_df = level_4_df.copy()\n",
    "    level_df = aa_lsae_count_df[aa_lsae_count_df['level'] == 5].copy()\n",
    "    level_df = make_aa_df_square(count_variable, level_df, hierarchy_df, 5, 5)\n",
    "    level_5_df = rake_level(count_variable, level_df, level_m1_df, problematic_rules, hierarchy_df, level = 5)\n",
    "    # Make aa_full_df\n",
    "    aa_full_count_df = pd.concat([\n",
    "        aa_gbd_count_0_to_3_df,\n",
    "        level_4_df,\n",
    "        level_5_df\n",
    "    ], ignore_index=True)\n",
    "    # Drop level column if it exists\n",
    "    if 'level' in aa_full_count_df.columns:\n",
    "        aa_full_count_df = aa_full_count_df.drop(columns=['level'])\n",
    "\n",
    "    # Save the aa_full_df\n",
    "    if aa_full_count_df_path is not None:\n",
    "        write_parquet(aa_full_count_df, aa_full_count_df_path)\n",
    "    # Return the full DataFrame if requested, return nothing otherwise\n",
    "    if return_full_df:\n",
    "        return aa_full_count_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-mbp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
