{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0c7df118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from rra_tools.shell_tools import mkdir  # type: ignore\n",
    "from idd_forecast_mbp import constants as rfc\n",
    "from idd_forecast_mbp.helper_functions import load_yaml_dictionary, parse_yaml_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "511ad7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2_HIERARCHY = \"lsae_1209\"\n",
    "\n",
    "GBD_INPUT_PATH = rfc.MODEL_ROOT / \"01-raw_data\" / \"gbd\"\n",
    "A2_INPUT_PATH = rfc.MODEL_ROOT / \"02-processed_data\" / A2_HIERARCHY\n",
    "OUTPUT_PATH = rfc.MODEL_ROOT / \"02-processed_data\" / \"gbd\"\n",
    "HIERARCHY_PATH = \"/mnt/team/rapidresponse/pub/population-model/admin-inputs/raking/gbd-inputs/hierarchy_{hierarchy}.parquet\"\n",
    "\n",
    "LSAE_population_path = \"/mnt/team/rapidresponse/pub/climate-aggregates/2025_03_20/results/lsae_1209/population.parquet\"\n",
    "lsae_hierarchy_path = HIERARCHY_PATH.format(hierarchy=A2_HIERARCHY)\n",
    "gbd_hierarchy_path = HIERARCHY_PATH.format(hierarchy=\"gbd_2023\")\n",
    "\n",
    "malaria_gbd_df_path = GBD_INPUT_PATH / \"gbd_2023_malaria_aa.csv\"\n",
    "dengue_gbd_df_path = GBD_INPUT_PATH / \"gbd_2023_dengue_aa.csv\"\n",
    "\n",
    "malaria_variables = {\n",
    "    \"pfpr\": f\"{A2_INPUT_PATH}/malaria_pfpr_mean_cc_insensitive.parquet\",\n",
    "    \"incidence\": f\"{A2_INPUT_PATH}/malaria_pf_inc_rate_mean_cc_insensitive.parquet\",\n",
    "    \"mortality\": f\"{A2_INPUT_PATH}/malaria_pf_mort_rate_mean_cc_insensitive.parquet\",\n",
    "}\n",
    "dengue_variables = {\n",
    "    \"denv_suit\": f\"{A2_INPUT_PATH}/dengue_suitability_mean_cc_insensitive.parquet\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81588197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_path_to_top_parent(path):\n",
    "    \"\"\"\n",
    "    Split the path_to_top_parent string into a list of integers\n",
    "    \"\"\"\n",
    "    return [int(x) for x in path.split(\",\") if x.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fb4c9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsae_hierarchy_df = pd.read_parquet(lsae_hierarchy_path)\n",
    "lsae_most_detailed_hierarchy_df = lsae_hierarchy_df[lsae_hierarchy_df[\"most_detailed\"] == 1].reset_index(drop=True)\n",
    "gbd_hierarchy_df = pd.read_parquet(gbd_hierarchy_path)\n",
    "gbd_most_detailed_hierarchy_df = gbd_hierarchy_df[gbd_hierarchy_df[\"most_detailed\"] == 1]\n",
    "lsae_path_to_hierarchy = lsae_most_detailed_hierarchy_df[\"path_to_top_parent\"].apply(split_path_to_top_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eb09e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row of gbd_most_detailed_hierarchy_df, find the rows of lsae_most_detailed_hierarchy_df that contain the location_id in the gbd row\n",
    "gbd_to_lsae_mapping = {}\n",
    "\n",
    "# Create a more efficient lookup structure\n",
    "lsae_paths_dict = {}\n",
    "for idx, row in lsae_most_detailed_hierarchy_df.iterrows():\n",
    "    lsae_location_id = row['location_id']\n",
    "    path = lsae_path_to_hierarchy.iloc[idx]\n",
    "    lsae_paths_dict[lsae_location_id] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8d226ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each GBD location_id, find LSAE locations that contain it in their path\n",
    "for _, gbd_row in gbd_most_detailed_hierarchy_df.iterrows():\n",
    "    gbd_location_id = gbd_row['location_id']\n",
    "    matching_lsae_locations = []\n",
    "    \n",
    "    for lsae_location_id, path in lsae_paths_dict.items():\n",
    "        if gbd_location_id in path:\n",
    "            matching_lsae_locations.append(lsae_location_id)\n",
    "    \n",
    "    gbd_to_lsae_mapping[gbd_location_id] = matching_lsae_locations\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "gbd_to_lsae_df = pd.DataFrame([\n",
    "    {'gbd_location_id': gbd_id, 'lsae_location_id': lsae_id}\n",
    "    for gbd_id, lsae_ids in gbd_to_lsae_mapping.items()\n",
    "    for lsae_id in lsae_ids\n",
    "])\n",
    "# rename lsae_location_id to location_id\n",
    "gbd_to_lsae_df.rename(columns={'lsae_location_id': 'location_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "db9b4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsae_population_df = pd.read_parquet(LSAE_population_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "707726e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_scenario_population_mean(df):\n",
    "    \"\"\"\n",
    "    Drop scenario, population, and any column with the word \"mean\" in it\n",
    "    \"\"\"\n",
    "    df = df.drop(columns=[\"scenario\", \"population\"])\n",
    "    df = df.loc[:, ~df.columns.str.contains(\"mean\")]\n",
    "    return df\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"\n",
    "    Rename columns in the df\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if \"_mean_per_capita\" in col:\n",
    "            df = df.rename(columns={col: col.replace(\"_mean_per_capita\", \"\")})\n",
    "        if \"rate_mean\" in col:\n",
    "            df = df.rename(columns={col: col.replace(\"rate_mean\", \"count\")})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fbcf6a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For malaria\n",
    "# Load the malaria pfpr data (it is a parquet file)\n",
    "malaria_pfpr = pd.read_parquet(malaria_variables[\"pfpr\"])\n",
    "# Rename malaria_pfpr_mean_per_capita to malaria_pfpr\n",
    "malaria_pfpr.rename(columns={\"malaria_pfpr_mean_per_capita\": \"malaria_pfpr\"}, inplace=True)\n",
    "malaria_pfpr = drop_scenario_population_mean(malaria_pfpr)\n",
    "# Load the malaria incidence data\n",
    "malaria_incidence = drop_scenario_population_mean(rename_columns(pd.read_parquet(malaria_variables[\"incidence\"])))\n",
    "# Load the malaria mortality data\n",
    "malaria_mortality = drop_scenario_population_mean(rename_columns(pd.read_parquet(malaria_variables[\"mortality\"])))\n",
    "malaria_df = pd.merge(pd.merge(malaria_pfpr, malaria_incidence, on=[\"location_id\", \"year_id\"]), malaria_mortality, on=[\"location_id\", \"year_id\"])\n",
    "# Write to parquet\n",
    "malaria_df.to_parquet(OUTPUT_PATH / \"raked_malaria_aa.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "25530884",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For dengue\n",
    "# Load the dengue suitability data\n",
    "dengue_suit = pd.read_parquet(dengue_variables[\"denv_suit\"])\n",
    "dengue_suit.rename(columns={\"dengue_suitability_mean_per_capita\": \"dengue_suit\"}, inplace=True)\n",
    "dengue_suit = drop_scenario_population_mean(dengue_suit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "52c1cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subset dengue_suit to location ides in lsae_most_detailed_hierarchy_df\n",
    "dengue_suit = dengue_suit[dengue_suit[\"location_id\"].isin(lsae_most_detailed_hierarchy_df[\"location_id\"])]\n",
    "dengue_suit = dengue_suit.merge(lsae_population_df[[\"location_id\", \"year_id\", \"population\"]], on=[\"location_id\", \"year_id\"], how=\"left\")\n",
    "dengue_suit['dengue_suit_population'] = dengue_suit['dengue_suit'] * dengue_suit['population']\n",
    "dengue_suit = dengue_suit.merge(gbd_to_lsae_df, on=\"location_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a2629a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_suit_by_gbd = dengue_suit.groupby(['year_id', 'gbd_location_id'])['dengue_suit_population'].sum().reset_index()\n",
    "dengue_suit_by_gbd.rename(columns={'gbd_location_id': 'location_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bb842614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_591565/1308516786.py:3: DtypeWarning: Columns (32,38,41) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dengue_gbd_df = pd.read_csv(dengue_gbd_df_path)\n"
     ]
    }
   ],
   "source": [
    "# Load the dengue incidence data (dengue_gbd_df_path)\n",
    "# It is a csv file, so we need to load it with pd.read_csv\n",
    "dengue_gbd_df = pd.read_csv(dengue_gbd_df_path)\n",
    "dengue_gbd_df = dengue_gbd_df[[\"location_id\", \"year_id\", \"most_detailed\", \"measure_id\", \"metric_id\", \"val\"]]\n",
    "# Remove all nan rows\n",
    "dengue_gbd_df = dengue_gbd_df.dropna(subset=[\"location_id\", \"year_id\", \"most_detailed\", \"measure_id\", \"metric_id\", \"val\"])\n",
    "# Subset dengue_incidence to most_detailed = 1 locations\n",
    "dengue_gbd_df = dengue_gbd_df[(dengue_gbd_df[\"most_detailed\"] == 1) & \n",
    "                              (dengue_gbd_df[\"metric_id\"] == 1) &\n",
    "                              (dengue_gbd_df[\"measure_id\"].isin([1,6]))].reset_index()  # 1 for mortality, 6 for incidence\n",
    "# Get all location_ids from the dengue incidence data\n",
    "# Drop the index most_detailed, and metric_id columns\n",
    "dengue_gbd_df = dengue_gbd_df.drop(columns=[\"index\", \"most_detailed\", \"metric_id\"])\n",
    "dengue_suit_by_gbd = dengue_suit_by_gbd.merge(\n",
    "    dengue_gbd_df[dengue_gbd_df['measure_id'] == 1].rename(columns={'val': 'denv_mort'}).drop(columns=['measure_id']), \n",
    "    on=[\"location_id\", \"year_id\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "dengue_suit_by_gbd = dengue_suit_by_gbd.merge(\n",
    "    dengue_gbd_df[dengue_gbd_df['measure_id'] == 6].rename(columns={'val': 'denv_inc'}).drop(columns=['measure_id']), \n",
    "    on=[\"location_id\", \"year_id\"], \n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "67a53bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_suit_by_gbd['mort_rf'] = dengue_suit_by_gbd['denv_mort'] / dengue_suit_by_gbd['dengue_suit_population']\n",
    "dengue_suit_by_gbd['inc_rf'] = dengue_suit_by_gbd['denv_inc'] / dengue_suit_by_gbd['dengue_suit_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5e26a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_suit_by_gbd['mort_rf'] = dengue_suit_by_gbd['denv_mort'] / dengue_suit_by_gbd['dengue_suit_population']\n",
    "dengue_suit_by_gbd['inc_rf'] = dengue_suit_by_gbd['denv_inc'] / dengue_suit_by_gbd['dengue_suit_population']\n",
    "# Set all places where dengue_suit_population is 0 to 0 for both mortality and incidence\n",
    "dengue_suit_by_gbd.loc[dengue_suit_by_gbd['dengue_suit_population'] == 0, ['mort_rf', 'inc_rf']] = 0\n",
    "# Drop the dengue_suit_population column\n",
    "dengue_suit_by_gbd = dengue_suit_by_gbd.drop(columns=['dengue_suit_population', 'denv_mort', 'denv_inc'])\n",
    "# Rename location_id to gbd_location_id\n",
    "dengue_suit_by_gbd.rename(columns={'location_id': 'gbd_location_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "16c4844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df = dengue_suit.merge(dengue_suit_by_gbd, on=[\"gbd_location_id\", \"year_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "912b5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df['dengue_mort_count'] = dengue_df['dengue_suit_population'] * dengue_df['mort_rf']\n",
    "dengue_df['dengue_inc_count'] = dengue_df['dengue_suit_population'] * dengue_df['inc_rf']\n",
    "dengue_df['dengue_mort_rate'] = dengue_df['dengue_mort_count'] / dengue_df['population']\n",
    "dengue_df['dengue_inc_rate'] = dengue_df['dengue_inc_count'] / dengue_df['population']\n",
    "# Drop the dengue_suit_population column\n",
    "dengue_df = dengue_df.drop(columns=['dengue_suit', 'dengue_suit_population', 'mort_rf', 'inc_rf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a5e09ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_df.to_parquet(OUTPUT_PATH / \"raked_dengue_aa.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-mbp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
