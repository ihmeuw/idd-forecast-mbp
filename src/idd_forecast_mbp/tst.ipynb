{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d97673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr # type: ignore\n",
    "from pathlib import Path\n",
    "import numpy as np # type: ignore\n",
    "from affine import Affine # type: ignore\n",
    "from typing import cast\n",
    "import numpy.typing as npt # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "from typing import Literal, NamedTuple\n",
    "import itertools\n",
    "from rra_tools.shell_tools import mkdir # type: ignore\n",
    "from idd_forecast_mbp import constants as rfc\n",
    "from idd_forecast_mbp.helper_functions import read_parquet_with_integer_ids, write_hdf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28492cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"Add DAH Sceanrios and create draw level dataframes for forecating malaria\")\n",
    "\n",
    "# # Define arguments\n",
    "# parser.add_argument(\"--cause\", type=str, required=False, default=\"malaria\", help=\"Cause (e.g., 'malaria', 'dengue')\")\n",
    "# parser.add_argument(\"--ssp_scenario\", type=str, required=True, help=\"SSP scenario (e.g., 'ssp126', 'ssp245', 'ssp585')\")\n",
    "# parser.add_argument(\"--dah_scenario\", type=str, required=False, default=\"Baseline\", help=\"DAH scenario (e.g., 'Baseline')\")\n",
    "# parser.add_argument(\"--measure\", type=str, required=False, default=\"mortality\", help=\"measure (e.g., 'mortality', 'incidence')\")\n",
    "# parser.add_argument(\"--metric\", type=str, required=False, default=\"rate\", help=\"metric (e.g., 'rate', 'count')\")\n",
    "# parser.add_argument(\"--fhs_flag\", type=int, required=False, default=0, help=\"Flag to indicate if output will follow FHS format\")\n",
    "# parser.add_argument(\"--run_date\", type=str, required=True, default=2025_06_25, help=\"Run date in format YYYY_MM_DD (e.g., '2025_06_25')\")\n",
    "\n",
    "\n",
    "# # Parse arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# cause = args.cause\n",
    "# ssp_scenario = args.ssp_scenario\n",
    "# dah_scenario = args.dah_scenario\n",
    "# measure = args.measure\n",
    "# metric = args.metric\n",
    "# fhs_flag = args.fhs_flag\n",
    "# run_date = args.run_date\n",
    "\n",
    "cause = \"malaria\"\n",
    "ssp_scenario = \"ssp126\"\n",
    "dah_scenario = \"Baseline\"\n",
    "measure = \"mortality\"\n",
    "metric = \"rate\"\n",
    "fhs_flag = 0\n",
    "run_date = \"2025_06_25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2475f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload folder: /mnt/team/idd/pub/forecast-mbp/05-upload_data/upload_folders/2025_06_25/as_cause_malaria_measure_mortality_metric_rate_ssp_scenario_ssp126_dah_scenario_Baseline\n",
      "Processing SSP scenario: ssp126\n",
      "Scenario: 66\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DATA_PATH = rfc.MODEL_ROOT / \"02-processed_data\"\n",
    "MODELING_DATA_PATH = rfc.MODEL_ROOT / \"03-modeling_data\"\n",
    "FORECASTING_DATA_PATH = rfc.MODEL_ROOT / \"04-forecasting_data\"\n",
    "UPLOAD_DATA_PATH = rfc.MODEL_ROOT / \"05-upload_data\"\n",
    "FHS_DATA_PATH = f\"{PROCESSED_DATA_PATH}/age_specific_fhs\"\n",
    "\n",
    "\n",
    "\n",
    "ssp_draws = rfc.draws\n",
    "measure_map = rfc.measure_map\n",
    "metric_map = rfc.metric_map\n",
    "cause_map = rfc.cause_map\n",
    "ssp_scenarios = rfc.ssp_scenarios\n",
    "fhs_draws = rfc.fhs_draws\n",
    "as_merge_variables = rfc.as_merge_variables\n",
    "scenario = ssp_scenarios[ssp_scenario][\"dhs_scenario\"] #  is the DHS scenario name\n",
    "\n",
    "release_id = 9\n",
    "\n",
    "cause_id = cause_map[cause][\"cause_id\"]\n",
    "measure_id = measure_map[measure][\"measure_id\"]\n",
    "metric_id = metric_map[metric][\"metric_id\"]\n",
    "\n",
    "if cause == \"malaria\":\n",
    "    processed_forecast_df_path_template = \"{UPLOAD_DATA_PATH}/full_as_malaria_measure_{measure}_ssp_scenario_{ssp_scenario}_dah_scenario_{dah_scenario}_draw_{draw}_with_predictions.parquet\"\n",
    "    if fhs_flag == 1:\n",
    "        upload_folder_path = f\"{UPLOAD_DATA_PATH}/fhs_upload_folders/cause_id_{cause_id}_measure_id_{measure_id}_scenario_{scenario}_{run_date}\"\n",
    "        upload_file_path = f\"{upload_folder_path}/draws.h5\"\n",
    "    else:\n",
    "        upload_folder_path = f\"{UPLOAD_DATA_PATH}/upload_folders/{run_date}/as_cause_{cause}_measure_{measure}_metric_{metric}_ssp_scenario_{ssp_scenario}_dah_scenario_{dah_scenario}\"\n",
    "        upload_file_path = f\"{upload_folder_path}/draws.h5\"\n",
    "else:\n",
    "    processed_forecast_df_path_template = \"{UPLOAD_DATA_PATH}/full_as_dengue_measure_{measure}_ssp_scenario_{ssp_scenario}_draw_{draw}_with_predictions.parquet\"\n",
    "    if fhs_flag == 1:\n",
    "        upload_folder_path = f\"{UPLOAD_DATA_PATH}/fhs_upload_folders/cause_id_{cause_id}_measure_id_{measure_id}_scenario_{scenario}_{run_date}\"\n",
    "        upload_file_path = f\"{upload_folder_path}/draws.h5\"\n",
    "    else:\n",
    "        upload_folder_path = f\"{UPLOAD_DATA_PATH}/upload_folders/{run_date}/as_cause_{cause}_measure_{measure}_metric_{metric}_ssp_scenario_{ssp_scenario}\"\n",
    "        upload_file_path = f\"{upload_folder_path}/draws.h5\"\n",
    "\n",
    "print(f\"Upload folder: {upload_folder_path}\")\n",
    "\n",
    "age_metadata_path = f\"{FHS_DATA_PATH}/age_metadata.parquet\"\n",
    "\n",
    "# Hierarchy path\n",
    "hierarchy_df_path = f'{PROCESSED_DATA_PATH}/full_hierarchy_lsae_1209.parquet'\n",
    "hierarchy_df = read_parquet_with_integer_ids(hierarchy_df_path)\n",
    "\n",
    "as_full_population_df_path = f\"{PROCESSED_DATA_PATH}/as_2023_full_population.parquet\"\n",
    "as_merge_variables = rfc.as_merge_variables\n",
    "fhs_hierarchy_df = hierarchy_df[hierarchy_df[\"in_fhs_hierarchy\"] == True].copy()\n",
    "\n",
    "all_location_ids = hierarchy_df[\"location_id\"].unique().tolist()\n",
    "fhs_location_ids = fhs_hierarchy_df[\"location_id\"].unique().tolist()\n",
    "\n",
    "year_ids = range(2022, 2101)\n",
    "# Make filters based on fhs_hierarchy_df and hierarchy_df\n",
    "fhs_location_filter = ('location_id', 'in', fhs_location_ids)\n",
    "all_location_filter = ('location_id', 'in', all_location_ids)\n",
    "\n",
    "if fhs_flag == 1:\n",
    "    location_filter = fhs_location_filter\n",
    "else:\n",
    "    location_filter = all_location_filter\n",
    "\n",
    "year_filter = ('year_id', 'in', year_ids)\n",
    "\n",
    "print(f\"Processing SSP scenario: {ssp_scenario}\")\n",
    "scenario = ssp_scenarios[ssp_scenario][\"dhs_scenario\"]\n",
    "print(f\"Scenario: {scenario}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d302992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the template with the first draw\n",
    "if cause == \"malaria\":\n",
    "    processed_forecast_df_path = processed_forecast_df_path_template.format(\n",
    "        UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "        measure=measure,\n",
    "        ssp_scenario=ssp_scenario,\n",
    "        dah_scenario=dah_scenario,\n",
    "        draw=\"000\"\n",
    "    )\n",
    "else:\n",
    "    processed_forecast_df_path = processed_forecast_df_path_template.format(\n",
    "        UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "        measure=measure,\n",
    "        ssp_scenario=ssp_scenario,\n",
    "        draw=\"000\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "328aaa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_df = read_parquet_with_integer_ids(processed_forecast_df_path,\n",
    "        filters=[[location_filter, year_filter]]  # Combining with AND logic\n",
    "    )\n",
    "\n",
    "fhs_draw_name = \"draw_0\"\n",
    "if metric == \"rate\":\n",
    "    upload_df[fhs_draw_name] = upload_df[\"count_pred\"] / upload_df[\"population\"]\n",
    "    upload_df = upload_df.drop(columns=[\"count_pred\", \"level\"])\n",
    "else:\n",
    "    upload_df[fhs_draw_name] = upload_df[\"count_pred\"]\n",
    "    upload_df = upload_df.drop(columns=[\"level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "331b25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upload_df = upload_df[as_merge_variables + [\"population\"] + [fhs_draw_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f00fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute paths\n",
    "draw_paths = []\n",
    "for ssp_draw in ssp_draws[1:]:\n",
    "    if cause == \"malaria\":\n",
    "        path = processed_forecast_df_path_template.format(\n",
    "            UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "            measure=measure,\n",
    "            ssp_scenario=ssp_scenario,\n",
    "            dah_scenario=dah_scenario,\n",
    "            draw=ssp_draw\n",
    "        )\n",
    "    else:\n",
    "        path = processed_forecast_df_path_template.format(\n",
    "            UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "            measure=measure,\n",
    "            ssp_scenario=ssp_scenario,\n",
    "            draw=ssp_draw\n",
    "        )\n",
    "    draw_paths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eba90d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating new columns to upload_df\n"
     ]
    }
   ],
   "source": [
    "needed_cols = [\"count_pred\"]\n",
    "if metric == \"rate\":\n",
    "    needed_cols.append(\"population\")\n",
    "\n",
    "draw_data = []\n",
    "for ssp_draw, draw_path in zip(ssp_draws[1:], draw_paths):\n",
    "    draw_df = read_parquet_with_integer_ids(\n",
    "        draw_path,\n",
    "        filters=[[location_filter, year_filter]],\n",
    "        columns=needed_cols  # Only read what you need\n",
    "    )\n",
    "    \n",
    "    if metric == \"rate\":\n",
    "        draw_data.append(draw_df[\"count_pred\"] / draw_df[\"population\"])\n",
    "    else:\n",
    "        draw_data.append(draw_df[\"count_pred\"])\n",
    "\n",
    "# Create all draw columns at once\n",
    "draw_names = [f\"draw_{int(draw)}\" for draw in ssp_draws[1:]]\n",
    "new_columns = pd.DataFrame(dict(zip(draw_names, draw_data)))\n",
    "# Concatenate the new columns to the upload_df\n",
    "print(\"Concatenating new columns to upload_df\")\n",
    "upload_df = pd.concat([upload_df, new_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945a81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "## Complete df with zero malaria data\n",
    "######\n",
    "age_metadata_df = read_parquet_with_integer_ids(age_metadata_path)\n",
    "age_group_ids = age_metadata_df[\"age_group_id\"].unique()\n",
    "sex_ids = [1, 2]  # 1\n",
    "missing_location_ids = set(fhs_location_ids) - set(upload_df[\"location_id\"].unique())\n",
    "combinations = list(itertools.product(age_group_ids, sex_ids, year_ids, missing_location_ids))\n",
    "zero_df = pd.DataFrame(combinations, columns=as_merge_variables)\n",
    "\n",
    "# Create a DataFrame with all draw columns initialized to 0.0\n",
    "draw_columns_df = pd.DataFrame(0.0, \n",
    "    index=range(len(zero_df)),\n",
    "    columns=fhs_draws)\n",
    "    \n",
    "# Then concatenate horizontally with your original DataFrame\n",
    "zero_df = pd.concat([zero_df, draw_columns_df], axis=1)\n",
    "\n",
    "missing_location_filter = ('location_id', 'in', list(missing_location_ids))\n",
    "year_filter = ('year_id', 'in', year_ids)\n",
    "as_population_df = read_parquet_with_integer_ids(as_full_population_df_path,\n",
    "                                               filters = [missing_location_filter, year_filter])\n",
    "\n",
    "zero_df = zero_df.merge(\n",
    "    as_population_df,\n",
    "    on=as_merge_variables,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "columns_to_keep = as_merge_variables + fhs_draws\n",
    "zero_df = zero_df[columns_to_keep]\n",
    "upload_df = pd.concat([upload_df, zero_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7c7c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc5d9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "## Fix Ethiopian location\n",
    "######\n",
    "\n",
    "swap_location_ids = [60908, 95069, 94364]\n",
    "replace_location_id = [44858]\n",
    "\n",
    "# Remove rows with swap_location_ids and store them separately\n",
    "rows_to_aggregate = upload_df[upload_df['location_id'].isin(swap_location_ids)].copy()\n",
    "remaining_df = upload_df[~upload_df['location_id'].isin(swap_location_ids)].copy()\n",
    "\n",
    "if metric == \"rate\":\n",
    "    # Vectorized: multiply all draw columns at once\n",
    "    draw_cols = rows_to_aggregate[fhs_draws]\n",
    "    pop_col = rows_to_aggregate['population']\n",
    "    rows_to_aggregate[fhs_draws] = draw_cols.multiply(pop_col, axis=0)\n",
    "\n",
    "\n",
    "# Aggregate the removed rows by year, age_group_id, and sex_id\n",
    "agg_dict = {\n",
    "    'population': 'sum',\n",
    "    **{col: 'sum' for col in fhs_draws}\n",
    "}\n",
    "\n",
    "aggregated_data = rows_to_aggregate.groupby(['year_id', 'age_group_id', 'sex_id']).agg(agg_dict).reset_index()\n",
    "\n",
    "if metric == \"rate\":\n",
    "    # Vectorized: divide all draw columns at once\n",
    "    draw_cols = aggregated_data[fhs_draws] \n",
    "    pop_col = aggregated_data['population']\n",
    "    aggregated_data[fhs_draws] = draw_cols.div(pop_col, axis=0)\n",
    "\n",
    "# Add the new location_id\n",
    "aggregated_data = aggregated_data.assign(location_id=replace_location_id[0])\n",
    "aggregated_data = aggregated_data[remaining_df.columns].copy()\n",
    "\n",
    "upload_df = pd.concat([remaining_df, aggregated_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad552633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving upload data for ssp126 ssp_scenario\n",
      "Saving upload data for Baseline dah_scenario\n",
      "Creating upload folder: /mnt/team/idd/pub/forecast-mbp/05-upload_data/upload_folders/2025_06_25/as_cause_malaria_measure_mortality_metric_rate_ssp_scenario_ssp126_dah_scenario_Baseline\n",
      "ðŸ“Š Calculating checksum for 44251850 rows...\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Upload\n",
    "######\n",
    "print(f\"Saving upload data for {ssp_scenario} ssp_scenario\")\n",
    "if cause == \"malaria\":\n",
    "    print(f\"Saving upload data for {dah_scenario} dah_scenario\")\n",
    "\n",
    "print(f\"Creating upload folder: {upload_folder_path}\")\n",
    "mkdir(upload_folder_path, exist_ok=True, parents=True)\n",
    "\n",
    "# Get draw columns before the conditional block\n",
    "draw_cols = upload_df.columns[upload_df.columns.str.startswith('draw_')].tolist()\n",
    "\n",
    "if fhs_flag == 1:\n",
    "    upload_df[\"release_id\"] = release_id\n",
    "    upload_df['scenario'] = scenario\n",
    "    upload_df[\"measure_id\"] = measure_id\n",
    "    upload_df[\"metric_id\"] = metric_id\n",
    "    upload_df[\"cause_id\"] = cause_id\n",
    "    columns_to_select = [\"measure_id\", \"metric_id\", \"cause_id\", \"location_id\", \"year_id\", \"age_group_id\", \"sex_id\", \"release_id\", \"scenario\"] + draw_cols\n",
    "    upload_df = upload_df[columns_to_select]\n",
    "    write_hdf(upload_df, upload_file_path, \n",
    "        data_columns= as_merge_variables)\n",
    "else:\n",
    "    upload_df['measure'] = measure\n",
    "    upload_df['metric'] = metric\n",
    "    upload_df['cause'] = cause\n",
    "    upload_df['ssp_scenario'] = ssp_scenario\n",
    "    if cause == \"malaria\":\n",
    "        upload_df['dah_scenario'] = dah_scenario\n",
    "        columns_to_select = ['location_id', 'year_id', 'age_group_id', 'sex_id', 'measure', 'metric', 'cause', 'ssp_scenario', 'dah_scenario', 'population'] + draw_cols\n",
    "        upload_df = upload_df[columns_to_select]\n",
    "        write_hdf(upload_df, upload_file_path, \n",
    "            data_columns=as_merge_variables + ['population'])\n",
    "    else:\n",
    "        columns_to_select = ['location_id', 'year_id', 'age_group_id', 'sex_id', 'measure', 'metric', 'cause', 'ssp_scenario', 'population'] + draw_cols\n",
    "        upload_df = upload_df[columns_to_select]\n",
    "        write_hdf(upload_df, upload_file_path, \n",
    "            data_columns=as_merge_variables + ['population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saved the age-sex-specific file\")\n",
    "\n",
    "if fhs_flag == 0:\n",
    "    print(f\"Starting aggregation from {len(upload_df)} rows...\")\n",
    "\n",
    "    # 2. Get draw columns more efficiently\n",
    "    draw_cols = [col for col in upload_df.columns if col.startswith('draw_')]\n",
    "    \n",
    "    # 3. Early check - exit if no population column when needed\n",
    "    has_population = 'population' in upload_df.columns\n",
    "    if metric_id == 3 and not has_population:\n",
    "        raise ValueError(\"Rate conversion requires population column\")\n",
    "    \n",
    "    # 4. Pre-create constant columns to avoid repeated operations\n",
    "    constant_cols = {\n",
    "        'measure': measure,\n",
    "        'metric': metric, \n",
    "        'cause': cause,\n",
    "        'ssp_scenario': ssp_scenario\n",
    "    }\n",
    "    if cause == \"malaria\":\n",
    "        constant_cols['dah_scenario'] = dah_scenario\n",
    "    \n",
    "    # 5. Create working DataFrame with only needed columns\n",
    "    groupby_cols = ['location_id', 'year_id']\n",
    "    needed_cols = groupby_cols + draw_cols\n",
    "    if has_population:\n",
    "        needed_cols.append('population')\n",
    "    \n",
    "    work_df = upload_df[needed_cols].copy()  # Only copy what we need\n",
    "    \n",
    "    # 6. Handle rate conversion BEFORE aggregation\n",
    "    if metric_id == 3 and has_population:\n",
    "        # Vectorized operation across all draw columns at once\n",
    "        work_df[draw_cols] = work_df[draw_cols].multiply(work_df['population'], axis=0)\n",
    "    \n",
    "    # 7. Optimize groupby with categoricals (only if many unique values)\n",
    "    if work_df['location_id'].nunique() > 100:  # Only categorize if beneficial\n",
    "        work_df['location_id'] = work_df['location_id'].astype('category')\n",
    "    if work_df['year_id'].nunique() > 10:\n",
    "        work_df['year_id'] = work_df['year_id'].astype('category')\n",
    "    \n",
    "    # 8. Fast aggregation with pre-built dict\n",
    "    agg_dict = {col: 'sum' for col in draw_cols}\n",
    "    if has_population:\n",
    "        agg_dict['population'] = 'sum'\n",
    "    \n",
    "    df_agg = work_df.groupby(groupby_cols, as_index=False, observed=True).agg(agg_dict)\n",
    "    \n",
    "    # 9. Convert back to rates AFTER aggregation\n",
    "    if metric_id == 3 and has_population:\n",
    "        df_agg[draw_cols] = df_agg[draw_cols].div(df_agg['population'], axis=0)\n",
    "    \n",
    "    print(f\"Aggregated to {len(df_agg)} rows\")\n",
    "    \n",
    "    # 10. Add constant columns efficiently\n",
    "    for col, value in constant_cols.items():\n",
    "        df_agg[col] = value\n",
    "    \n",
    "    # 11. Select columns in final order (avoid reordering)\n",
    "    if cause == \"malaria\":\n",
    "        final_cols = [\"measure\", \"metric\", \"cause\", \"location_id\", \"year_id\", \n",
    "                     \"ssp_scenario\", \"dah_scenario\", \"population\"] + draw_cols\n",
    "    else:\n",
    "        final_cols = [\"measure\", \"metric\", \"cause\", \"location_id\", \"year_id\", \n",
    "                     \"ssp_scenario\", \"population\"] + draw_cols\n",
    "    \n",
    "    df_agg = df_agg[final_cols]\n",
    "    \n",
    "    # 12. Build path more efficiently\n",
    "    path_parts = [\n",
    "        UPLOAD_DATA_PATH, \"upload_folders\", run_date,\n",
    "        f\"aa_cause_id_{cause_id}_measure_id_{measure_id}_metric_id_{metric_id}_ssp_scenario_{ssp_scenario}\"\n",
    "    ]\n",
    "    if cause == 'malaria':\n",
    "        path_parts[-1] += f\"_dah_scenario_{dah_scenario}\"\n",
    "    \n",
    "    aa_upload_folder_path = \"/\".join(path_parts)\n",
    "    aa_upload_file_path = f\"{aa_upload_folder_path}/draws.h5\"\n",
    "    \n",
    "    # 13. Create directory and save\n",
    "    mkdir(aa_upload_folder_path, exist_ok=True, parents=True)\n",
    "    \n",
    "    # 14. Only index columns that vary (skip constants)\n",
    "    variable_data_cols = []\n",
    "    for col in ['location_id', 'year_id', 'measure', 'metric', 'cause']:\n",
    "        if df_agg[col].nunique() > 1:\n",
    "            variable_data_cols.append(col)\n",
    "    \n",
    "    write_hdf(df_agg, aa_upload_file_path, data_columns=variable_data_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Saved the age-sex-specific file\")\n",
    "# Stopped here!\n",
    "if fhs_flag == 0:\n",
    "\n",
    "\n",
    "    upload_df = upload_df.copy()\n",
    "    # Get draw columns efficiently\n",
    "    draw_cols = upload_df.columns[upload_df.columns.str.startswith('draw_')].tolist()\n",
    "\n",
    "    # Handle rate conversion BEFORE aggregation if needed\n",
    "    if metric_id == 3 and 'population' in upload_df.columns:\n",
    "        # Vectorized operation across all draw columns\n",
    "        upload_df[draw_cols] = upload_df[draw_cols].multiply(upload_df['population'], axis=0)\n",
    "\n",
    "    # Use categorical grouping for speed\n",
    "    upload_df['location_id'] = upload_df['location_id'].astype('category')\n",
    "    upload_df['year_id'] = upload_df['year_id'].astype('category')\n",
    "\n",
    "    # Create aggregation dict efficiently\n",
    "    agg_dict = dict.fromkeys(draw_cols, 'sum')\n",
    "    if 'population' in upload_df.columns:\n",
    "        agg_dict['population'] = 'sum'\n",
    "\n",
    "    # Fast aggregation\n",
    "    df_agg = upload_df.groupby(['location_id', 'year_id'], as_index=False, observed=True).agg(agg_dict)\n",
    "\n",
    "    # Convert back to rates AFTER aggregation if needed\n",
    "    if metric_id == 3 and 'population' in df_agg.columns:\n",
    "        # Divide aggregated counts by aggregated population to get rates\n",
    "        df_agg[draw_cols] = df_agg[draw_cols].div(df_agg['population'], axis=0)\n",
    "\n",
    "    print(f\"Aggregated from {len(upload_df)} rows to {len(df_agg)} rows\")\n",
    "\n",
    "    if cause == 'malaria':\n",
    "        aa_upload_folder_path = f\"{UPLOAD_DATA_PATH}/upload_folders/{run_date}/aa_cause_id_{cause_id}_measure_id_{measure_id}_metric_id_{metric_id}_ssp_scenario_{ssp_scenario}_dah_scenario_{dah_scenario}\"\n",
    "    else:\n",
    "        aa_upload_folder_path = f\"{UPLOAD_DATA_PATH}/upload_folders/{run_date}/aa_cause_id_{cause_id}_measure_id_{measure_id}_metric_id_{metric_id}_ssp_scenario_{ssp_scenario}\"\n",
    "\n",
    "    aa_upload_file_path = f\"{aa_upload_folder_path}/draws.h5\"\n",
    "\n",
    "    df_agg['measure'] = measure\n",
    "    df_agg['metric'] = metric\n",
    "    df_agg['cause'] = cause\n",
    "    df_agg['ssp_scenario'] = ssp_scenario\n",
    "    df_agg['dah_scenario'] = dah_scenario\n",
    "\n",
    "    if cause == \"malaria\":\n",
    "        columns_to_select = [\"measure\", \"metric\", \"cause\", \"location_id\", \"year_id\", \"ssp_scenario\", \"dah_scenario\", \"population\"] + draw_cols\n",
    "    else:\n",
    "        columns_to_select = [\"measure\", \"metric\", \"cause\", \"location_id\", \"year_id\", \"ssp_scenario\", \"population\"] + draw_cols\n",
    "    df_agg = df_agg[columns_to_select]\n",
    "    mkdir(aa_upload_folder_path, exist_ok=True, parents=True)\n",
    "    # Set file permissions to be world-writable and deletable after saving\n",
    "    write_hdf(df_agg, aa_upload_file_path, \n",
    "          data_columns=['location_id', 'year_id', 'measure', 'metric', 'cause'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-mbp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
