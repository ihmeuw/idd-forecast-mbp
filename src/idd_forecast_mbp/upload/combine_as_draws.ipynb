{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "789f25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr # type: ignore\n",
    "from pathlib import Path\n",
    "import numpy as np # type: ignore\n",
    "from affine import Affine # type: ignore\n",
    "from typing import cast\n",
    "import numpy.typing as npt # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "from typing import Literal, NamedTuple\n",
    "import itertools\n",
    "from rra_tools.shell_tools import mkdir # type: ignore\n",
    "from idd_forecast_mbp import constants as rfc\n",
    "from idd_forecast_mbp.helper_functions import read_parquet_with_integer_ids\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a946721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description=\"Add DAH Sceanrios and create draw level dataframes for forecating malaria\")\n",
    "\n",
    "# # Define arguments\n",
    "# parser.add_argument(\"--cause\", type=str, required=False, default=\"malaria\", help=\"Cause (e.g., 'malaria', 'dengue')\")\n",
    "# parser.add_argument(\"--ssp_scenario\", type=str, required=True, help=\"SSP scenario (e.g., 'ssp126', 'ssp245', 'ssp585')\")\n",
    "# parser.add_argument(\"--dah_scenario\", type=str, required=False, default=\"Baseline\", help=\"DAH scenario (e.g., 'Baseline')\")\n",
    "# parser.add_argument(\"--measure\", type=str, required=False, default=\"mortality\", help=\"measure (e.g., 'mortality', 'incidence')\")\n",
    "# parser.add_argument(\"--metric\", type=str, required=False, default=\"rate\", help=\"metric (e.g., 'rate', 'count')\")\n",
    "# parser.add_argument(\"--fhs_flag\", type=int, required=False, default=0, help=\"Flag to indicate if output will follow FHS format\")\n",
    "\n",
    "# # Parse arguments\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# cause = args.cause\n",
    "# ssp_scenario = args.ssp_scenario\n",
    "# dah_scenario = args.dah_scenario\n",
    "# measure = args.measure\n",
    "# metric = args.metric\n",
    "# fhs_flag = args.fhs_flag\n",
    "cause = \"malaria\"\n",
    "ssp_scenario = \"ssp245\"\n",
    "dah_scenario = \"Baseline\"\n",
    "measure = \"incidence\"\n",
    "metric = \"rate\"\n",
    "fhs_flag = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f35c1088",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_PATH = rfc.MODEL_ROOT / \"02-processed_data\"\n",
    "MODELING_DATA_PATH = rfc.MODEL_ROOT / \"03-modeling_data\"\n",
    "FORECASTING_DATA_PATH = rfc.MODEL_ROOT / \"04-forecasting_data\"\n",
    "UPLOAD_DATA_PATH = rfc.MODEL_ROOT / \"05-upload_data\"\n",
    "FHS_DATA_PATH = f\"{PROCESSED_DATA_PATH}/age_specific_fhs\"\n",
    "\n",
    "run_date = \"2025_06_13\"\n",
    "\n",
    "ssp_draws = rfc.draws\n",
    "measure_map = rfc.measure_map\n",
    "metric_map = rfc.metric_map\n",
    "cause_map = rfc.cause_map\n",
    "ssp_scenarios = rfc.ssp_scenarios\n",
    "fhs_draws = rfc.fhs_draws\n",
    "scenario = ssp_scenarios[ssp_scenario][\"dhs_scenario\"] #  is the DHS scenario name\n",
    "\n",
    "release_id = 9\n",
    "\n",
    "cause_id = cause_map[cause][\"cause_id\"]\n",
    "measure_id = measure_map[measure][\"measure_id\"]\n",
    "metric_id = metric_map[metric][\"metric_id\"]\n",
    "\n",
    "future_fhs_population_path = \"/mnt/share/forecasting/data/9/future/population/20250606_first_sub_rcp45_climate_ref_100d_hiv_shocks_covid_all/summary/summary.nc\"\n",
    "future_fhs_population = xr.open_dataset(future_fhs_population_path)\n",
    "# The actual data is in the 'draws' variable, select the 'mean' statistic\n",
    "fhs_pop_data = future_fhs_population['draws'].sel(statistic='mean')\n",
    "future_fhs_population_df = fhs_pop_data.to_dataframe().reset_index()\n",
    "future_fhs_population_df = future_fhs_population_df.rename(columns={\"draws\": \"population\"})\n",
    "future_fhs_population_df = future_fhs_population_df.drop(columns=[\"scenario\"], errors='ignore')\n",
    "# Drop the 'statistic' column as it is no longer needed\n",
    "future_fhs_population_df = future_fhs_population_df.drop(columns=[\"statistic\"], errors='ignore')\n",
    "\n",
    "processed_forecast_df_path = \"{UPLOAD_DATA_PATH}/full_as_malaria_measure_{measure}_ssp_scenario_{ssp_scenario}_dah_scenario_{dah_scenario}_draw_{draw}_with_predictions.parquet\"\n",
    "\n",
    "if fhs_flag == 1:\n",
    "    upload_folder_path = f\"{UPLOAD_DATA_PATH}/fhs_upload_folders/cause_id_{cause_id}_measure_id_{measure_id}_scenario_{scenario}_{run_date}\"\n",
    "    upload_file_path = f\"{upload_folder_path}/draws.h5\"\n",
    "else:\n",
    "    upload_folder_path = f\"{UPLOAD_DATA_PATH}/upload_folders/cause_id_{cause_id}_measure_id_{measure_id}_metric_id_{metric_id}_ssp_scenario_{ssp_scenario}_dah_scenario_{dah_scenario}_{run_date}\"\n",
    "    upload_file_path = f\"{upload_folder_path}/draws.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d179cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload folder: /mnt/team/idd/pub/forecast-mbp/05-upload_data/fhs_upload_folders/cause_id_345_measure_id_6_scenario_0_2025_06_13\n",
      "Processing SSP scenario: ssp245\n",
      "Scenario: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Upload folder: {upload_folder_path}\")\n",
    "\n",
    "age_metadata_path = f\"{FHS_DATA_PATH}/age_metadata.parquet\"\n",
    "# Hierarchy path\n",
    "hierarchy_df_path = f'{PROCESSED_DATA_PATH}/full_hierarchy_lsae_1209.parquet'\n",
    "hierarchy_df = read_parquet_with_integer_ids(hierarchy_df_path)\n",
    "fhs_hierarchy_df = hierarchy_df[hierarchy_df[\"in_fhs_hierarchy\"] == True].copy()\n",
    "\n",
    "all_location_ids = hierarchy_df[\"location_id\"].unique().tolist()\n",
    "fhs_location_ids = fhs_hierarchy_df[\"location_id\"].unique().tolist()\n",
    "year_ids = range(2022, 2101)\n",
    "# Make filters based on fhs_hierarchy_df and hierarchy_df\n",
    "fhs_location_filter = ('location_id', 'in', fhs_location_ids)\n",
    "all_location_filter = ('location_id', 'in', all_location_ids)\n",
    "\n",
    "if fhs_flag == 1:\n",
    "    location_filter = fhs_location_filter\n",
    "else:\n",
    "    location_filter = all_location_filter\n",
    "\n",
    "year_filter = ('year_id', 'in', year_ids)\n",
    "\n",
    "print(f\"Processing SSP scenario: {ssp_scenario}\")\n",
    "scenario = ssp_scenarios[ssp_scenario][\"dhs_scenario\"]\n",
    "print(f\"Scenario: {scenario}\")\n",
    "\n",
    "# Make the template with the first draw\n",
    "upload_df = read_parquet_with_integer_ids(\n",
    "        processed_forecast_df_path.format(\n",
    "            UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "            measure=measure,\n",
    "            ssp_scenario=ssp_scenario,\n",
    "            dah_scenario=dah_scenario,\n",
    "            draw=\"000\"\n",
    "        ),\n",
    "        filters=[[location_filter, year_filter]]  # Combining with AND logic\n",
    "    )\n",
    "\n",
    "if \"population_x\" in upload_df.columns:\n",
    "    upload_df = upload_df.rename(columns={\"population_y\": \"population\"})\n",
    "    upload_df = upload_df.drop(columns=[\"population_x\"])\n",
    "\n",
    "fhs_draw_name = \"draw_0\"\n",
    "if metric == \"rate\":\n",
    "    upload_df[fhs_draw_name] = upload_df[\"count_pred\"] / upload_df[\"population\"]\n",
    "else:\n",
    "    upload_df[fhs_draw_name] = upload_df[\"count_pred\"]\n",
    "\n",
    "# if fhs_flag:\n",
    "#     upload_df = upload_df.drop(columns=[\"population\"])\n",
    "\n",
    "upload_df = upload_df.drop(columns=[\"count_pred\", \"level\"])\n",
    "upload_df[\"measure_id\"] = measure_id\n",
    "upload_df[\"metric_id\"] = metric_id\n",
    "upload_df[\"cause_id\"] = cause_id\n",
    "upload_df[\"release_id\"] = release_id\n",
    "upload_df[\"scenario\"] = scenario\n",
    "upload_df[\"ssp_scenario\"] = ssp_scenario\n",
    "upload_df[\"dah_scenario\"] = dah_scenario\n",
    "\n",
    "upload_df = upload_df[[\"measure_id\", \"metric_id\", \"cause_id\", \"age_group_id\", \"sex_id\", \"location_id\", \"year_id\", \"ssp_scenario\", \"dah_scenario\", \"population\", fhs_draw_name]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb8eee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing draw 10\n",
      "Processing draw 20\n",
      "Processing draw 20\n",
      "Processing draw 30\n",
      "Processing draw 30\n",
      "Processing draw 40\n",
      "Processing draw 40\n",
      "Processing draw 50\n",
      "Processing draw 50\n",
      "Processing draw 60\n",
      "Processing draw 60\n",
      "Processing draw 70\n",
      "Processing draw 70\n",
      "Processing draw 80\n",
      "Processing draw 80\n",
      "Processing draw 90\n",
      "Processing draw 90\n"
     ]
    }
   ],
   "source": [
    "for ssp_draw in ssp_draws[1:]:\n",
    "    \n",
    "    draw_df_path = processed_forecast_df_path.format(\n",
    "        UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "        measure=measure,\n",
    "        ssp_scenario=ssp_scenario,\n",
    "        dah_scenario=dah_scenario,\n",
    "        draw=ssp_draw\n",
    "    )\n",
    "    draw_int = int(ssp_draw)\n",
    "    if draw_int % 10 == 0:\n",
    "        print(f\"Processing draw {draw_int}\")\n",
    "\n",
    "    draw_df = read_parquet_with_integer_ids(\n",
    "            draw_df_path,\n",
    "            filters=[[location_filter, year_filter]]  # Combining with AND logic\n",
    "        )\n",
    "    if \"population_x\" in draw_df.columns:\n",
    "        draw_df = draw_df.rename(columns={\"population_y\": \"population\"})\n",
    "        draw_df = draw_df.drop(columns=[\"population_x\"])\n",
    "\n",
    "    fhs_draw_name = f\"draw_{draw_int}\"\n",
    "    if metric == \"rate\":\n",
    "        draw_df[fhs_draw_name] = draw_df[\"count_pred\"] / draw_df[\"population\"]\n",
    "    else:\n",
    "        draw_df[fhs_draw_name] = draw_df[\"count_pred\"]\n",
    "    \n",
    "    draw_df = draw_df.drop(columns=[\"count_pred\", \"level\", \"population\"])\n",
    "\n",
    "    upload_df = upload_df.merge(\n",
    "        draw_df,\n",
    "        on = [\"location_id\", \"year_id\", \"age_group_id\", \"sex_id\"],\n",
    "        how = \"left\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95eb93f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "## Complete df with zero malaria data\n",
    "######\n",
    "age_metadata_df = read_parquet_with_integer_ids(age_metadata_path)\n",
    "age_group_ids = age_metadata_df[\"age_group_id\"].unique()\n",
    "sex_ids = [1, 2]  # 1\n",
    "missing_location_ids = set(fhs_location_ids) - set(upload_df[\"location_id\"].unique())\n",
    "combinations = list(itertools.product(age_group_ids, sex_ids, year_ids, missing_location_ids))\n",
    "zero_df = pd.DataFrame(combinations, columns=['age_group_id', 'sex_id', \"year_id\", \"location_id\"])\n",
    "zero_df[\"measure_id\"] = measure_id\n",
    "zero_df[\"metric_id\"] = metric_id\n",
    "zero_df[\"cause_id\"] = cause_id\n",
    "zero_df[\"release_id\"] = release_id\n",
    "zero_df[\"scenario\"] = scenario\n",
    "zero_df[\"ssp_scenario\"] = ssp_scenario\n",
    "zero_df[\"dah_scenario\"] = dah_scenario\n",
    "\n",
    "# Create a DataFrame with all draw columns initialized to 0.0\n",
    "draw_columns_df = pd.DataFrame(0.0, \n",
    "    index=range(len(zero_df)),\n",
    "    columns=fhs_draws)\n",
    "    \n",
    "# Then concatenate horizontally with your original DataFrame\n",
    "zero_df = pd.concat([zero_df, draw_columns_df], axis=1)\n",
    "\n",
    "zero_df = zero_df.merge(\n",
    "    future_fhs_population_df,\n",
    "    on=[\"location_id\", \"year_id\",\"age_group_id\", \"sex_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "zero_df = zero_df[[\"measure_id\", \"metric_id\", \"cause_id\", \"age_group_id\", \"sex_id\", \"location_id\", \"year_id\", \"ssp_scenario\", \"dah_scenario\", \"population\"] + fhs_draws]\n",
    "\n",
    "upload_df = pd.concat([upload_df, zero_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7653916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saveing upload data for ssp245 ssp_scenario\n",
      "Saveing upload data for Baseline dah_scenario\n",
      "Creating upload folder: /mnt/team/idd/pub/forecast-mbp/05-upload_data/fhs_upload_folders/cause_id_345_measure_id_6_scenario_0_2025_06_13\n",
      "Saved the age-sex-specific file\n",
      "Saved the age-sex-specific file\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "## Upload\n",
    "######\n",
    "print(f\"Saveing upload data for {ssp_scenario} ssp_scenario\")\n",
    "print(f\"Saveing upload data for {dah_scenario} dah_scenario\")\n",
    "\n",
    "# upload_folder_path = upload_folder_path_template.format(\n",
    "#     UPLOAD_DATA_PATH=UPLOAD_DATA_PATH,\n",
    "#     cause_id=cause_id,\n",
    "#     measure_id=measure_id,\n",
    "#     metric_id=metric_id,\n",
    "#     scenario=scenario,\n",
    "#     ssp_scenario=ssp_scenario,\n",
    "#     dah_scenario=dah_scenario,\n",
    "#     run_date=run_date\n",
    "# )\n",
    "print(f\"Creating upload folder: {upload_folder_path}\")\n",
    "mkdir(upload_folder_path, exist_ok=True, parents=True)\n",
    "# upload_file_path = upload_file_path_template.format(\n",
    "#     upload_folder_path=upload_folder_path\n",
    "# )\n",
    "\n",
    "if fhs_flag == 1:\n",
    "    draw_cols = upload_df.columns[upload_df.columns.str.startswith('draw_')].tolist()\n",
    "    upload_df[\"release_id\"] = release_id\n",
    "    upload_df['scenario'] = scenario\n",
    "    columns_to_select = [\"measure_id\", \"metric_id\", \"cause_id\", \"location_id\", \"year_id\", \"age_group_id\", \"sex_id\", \"release_id\", \"scenario\"] + draw_cols\n",
    "    upload_df = upload_df[columns_to_select]\n",
    "\n",
    "upload_df.to_hdf(\n",
    "    upload_file_path,\n",
    "    key='df', \n",
    "    mode='w', \n",
    "    format='table',\n",
    "    data_columns=['location_id', 'sex_id', 'age_group_id', 'year_id', 'measure_id', 'metric_id', 'cause_id']\n",
    ")\n",
    "os.chmod(upload_file_path, 0o775)\n",
    "print(\"Saved the age-sex-specific file\")\n",
    "\n",
    "if fhs_flag == 0:\n",
    "    upload_df = upload_df.copy()\n",
    "    # Get draw columns efficiently\n",
    "    draw_cols = upload_df.columns[upload_df.columns.str.startswith('draw_')].tolist()\n",
    "\n",
    "    # Handle rate conversion BEFORE aggregation if needed\n",
    "    if metric_id == 3 and 'population' in upload_df.columns:\n",
    "        # Vectorized operation across all draw columns\n",
    "        upload_df[draw_cols] = upload_df[draw_cols].multiply(upload_df['population'], axis=0)\n",
    "\n",
    "    # Use categorical grouping for speed\n",
    "    upload_df['location_id'] = upload_df['location_id'].astype('category')\n",
    "    upload_df['year_id'] = upload_df['year_id'].astype('category')\n",
    "\n",
    "    # Create aggregation dict efficiently\n",
    "    agg_dict = dict.fromkeys(draw_cols, 'sum')\n",
    "    if 'population' in upload_df.columns:\n",
    "        agg_dict['population'] = 'sum'\n",
    "\n",
    "    # Fast aggregation\n",
    "    df_agg = upload_df.groupby(['location_id', 'year_id'], as_index=False, observed=True).agg(agg_dict)\n",
    "\n",
    "    # Convert back to rates AFTER aggregation if needed\n",
    "    if metric_id == 3 and 'population' in df_agg.columns:\n",
    "        # Divide aggregated counts by aggregated population to get rates\n",
    "        df_agg[draw_cols] = df_agg[draw_cols].div(df_agg['population'], axis=0)\n",
    "\n",
    "    print(f\"Aggregated from {len(upload_df)} rows to {len(df_agg)} rows\")\n",
    "\n",
    "    aa_upload_folder_path = f\"{UPLOAD_DATA_PATH}/upload_folders/aa_cause_id_{cause_id}_measure_id_{measure_id}_metric_id_{metric_id}_ssp_scenario_{ssp_scenario}_dah_scenario_{dah_scenario}_{run_date}\"\n",
    "    aa_upload_file_path = f\"{aa_upload_folder_path}/draws.h5\"\n",
    "\n",
    "    df_agg['measure_id'] = measure_id\n",
    "    df_agg['metric_id'] = metric_id\n",
    "    df_agg['cause_id'] = cause_id\n",
    "    df_agg['ssp_scenario'] = ssp_scenario\n",
    "    df_agg['dah_scenario'] = dah_scenario\n",
    "\n",
    "    columns_to_select = [\"measure_id\", \"metric_id\", \"cause_id\", \"location_id\", \"year_id\", \"ssp_scenario\", \"dah_scenario\", \"population\"] + draw_cols\n",
    "    df_agg = df_agg[columns_to_select]\n",
    "    mkdir(aa_upload_folder_path, exist_ok=True, parents=True)\n",
    "    # Set file permissions to be world-writable and deletable after saving\n",
    "    df_agg.to_hdf(\n",
    "        aa_upload_file_path,\n",
    "        key='df', \n",
    "        mode='w', \n",
    "        format='table',\n",
    "        data_columns=['location_id', 'year_id', 'measure_id', 'metric_id', 'cause_id']\n",
    "    )\n",
    "    os.chmod(aa_upload_file_path, 0o775)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4663b3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forecast-mbp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
